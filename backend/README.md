# ðŸ–¥ Backend â€“ Smart Dataset Analyzer  

The **backend** is built with **FastAPI** and provides NLP/ML-powered **text analysis APIs** and **PDF export**.  

---

## ðŸš€ Features  
- **Text Preprocessing** â†’ tokenization, stop-word removal, lemmatization  
- **Topic Modeling** â†’ LDA, NMF  
- **Sentiment Analysis** â†’ TextBlob  
- **Vectorization** â†’ TF-IDF, BoW  
- **PDF Export** â†’ auto-generated summary report  

---

## ðŸ“‚ Structure  
backend/
â”‚â”€â”€ analyze_all.py # FastAPI main app
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ README.md

yaml
Copy code

Endpoints:  
- `POST /analyze-all` â†’ Upload + analyze dataset  
- `POST /download-report` â†’ Export PDF  

---

## ðŸ›  Setup & Run  

### Install dependencies  
```bash
cd backend
pip install -r requirements.txt
python -m spacy download en_core_web_sm
Start server
bash
Copy code
uvicorn analyze_all:app --reload --host 127.0.0.1 --port 8001
Server runs at â†’ http://localhost:8001/

ðŸ“„ Requirements
Python 3.8+

FastAPI, Uvicorn, scikit-learn, TextBlob, SpaCy, Pandas, NumPy, python-docx, fpdf

Example (requirements.txt):

txt
Copy code
fastapi
uvicorn
pandas
numpy
scikit-learn
textblob
spacy
python-docx
fpdf
yaml
Copy code

---

ðŸ‘‰ This way, your repo has:  

- `README.md` â†’ overview + project structure  
- `frontend/README.md` â†’ React/Tailwind details  
- `backend/README.md` â†’ FastAPI/NLP details  