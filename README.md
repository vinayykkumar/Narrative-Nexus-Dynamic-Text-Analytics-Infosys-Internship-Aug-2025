# ğŸ§  AI Narrative Nexus

> **Dynamic Text Analysis Platform for Advanced NLP Insights**

A comprehensive text analysis platform that combines cutting-edge machine learning with an intuitive web interface to extract themes, analyze sentiment, and generate actionable insights from textual data.

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Features](#-features)
- [Technology Stack](#-technology-stack)
- [Quick Start](#-quick-start)
- [Detailed Setup](#-detailed-setup)
- [Usage Guide](#-usage-guide)
- [Project Structure](#-project-structure)
- [Development](#-development)
- [Production Deployment](#-production-deployment)
- [Contributing](#-contributing)
- [License](#-license)

## ğŸ¯ Project Overview

AI Narrative Nexus is an 8-week development project aimed at creating a dynamic text analysis platform capable of processing various text inputs and providing comprehensive insights through:

- **Topic Modeling**: Identify key themes using LDA and NMF algorithms
- **Sentiment Analysis**: Assess emotional tone with 90%+ accuracy
- **Text Summarization**: Generate concise extractive and abstractive summaries
- **Interactive Visualizations**: Word clouds, sentiment distribution, topic graphs
- **Comprehensive Reporting**: Actionable insights and recommendations

### Project Timeline
- **Week 1-2**: âœ… Data Collection & Preprocessing (COMPLETE)
- **Week 3**: Topic Modeling Implementation
- **Week 4**: Sentiment Analysis
- **Week 5**: Insights Generation & Summarization
- **Week 6-7**: Visualization & Reporting
- **Week 8**: Final Evaluation & Documentation

## âœ¨ Features

### ğŸ”„ Data Processing Pipeline
- **Multi-format Input**: CSV, TSV, TXT, JSON, DOCX support
- **Professional Text Cleaning**: URL, email, mention, hashtag removal
- **Advanced Normalization**: Contraction expansion, stemming, lemmatization
- **NLTK Integration**: 179 stop words, Porter stemming
- **ML-Ready Output**: TF-IDF vectorization, feature extraction

### ğŸ¤– Machine Learning
- **Sentiment Analysis**: 94% accuracy on review data, 71% on social media
- **Multiple Algorithms**: Random Forest, SVM, Naive Bayes, Logistic Regression
- **Production Models**: Serialized models with vectorizers
- **Batch Processing**: Handle datasets up to 1M+ records

### ğŸ–¥ï¸ Web Interface
- **Modern UI**: Next.js 15 with TypeScript
- **Real-time Processing**: Interactive text preprocessing demo
- **File Upload**: Drag-and-drop interface with validation
- **Responsive Design**: Mobile-friendly with dark/light themes
- **Live Analytics**: Processing statistics and performance metrics

## ğŸ› ï¸ Technology Stack

### Frontend
- **Framework**: Next.js 15.2.4 with App Router
- **Language**: TypeScript
- **UI Components**: Radix UI + Tailwind CSS
- **Icons**: Lucide React
- **Charts**: Recharts
- **Themes**: next-themes

### Backend/ML
- **Language**: Python 3.13+
- **ML Framework**: scikit-learn 1.7.1
- **NLP Library**: NLTK 3.9.1
- **Data Processing**: pandas 2.3.2, numpy 2.3.2
- **Serialization**: joblib, pickle

### Development
- **Package Manager**: npm
- **Linting**: ESLint
- **Build Tool**: Next.js built-in
- **Environment**: Virtual environments for Python

## ğŸš€ Quick Start

### Prerequisites
- **Node.js** 20.19.2+ and npm
- **Python** 3.13+
- **Git**

### 1-Minute Setup
```bash
# Clone the repository
git clone https://github.com/0x1git/Nexus.git
cd Nexus

# Setup everything (automated)
./setup_preprocessing.sh

# Start the development server
npm install
npm run dev
```

Visit [http://localhost:3000](http://localhost:3000) to access the application.

## ğŸ“– Detailed Setup

### 1. Environment Setup

```bash
# Clone and navigate
git clone https://github.com/0x1git/Nexus.git
cd Nexus

# Install Node.js dependencies
npm install

# Setup Python environment
python3 -m venv python_preprocessing/venv
source python_preprocessing/venv/bin/activate  # On Windows: python_preprocessing\venv\Scripts\activate
```

### 2. Python Dependencies

```bash
# Activate virtual environment
source python_preprocessing/venv/bin/activate

# Install Python packages
pip install pandas numpy scikit-learn nltk joblib

# Download NLTK data
python3 -c "import nltk; nltk.download('punkt_tab'); nltk.download('stopwords'); nltk.download('wordnet')"
```

### 3. Dataset Preparation

```bash
# Create dataset directory
mkdir -p dataset

# Add your datasets (example structure):
# dataset/
# â”œâ”€â”€ amazon_alexa.tsv
# â”œâ”€â”€ twitter_sentiment.csv
# â””â”€â”€ your_custom_data.csv
```

### 4. Process Sample Data

```bash
# Activate Python environment
source python_preprocessing/venv/bin/activate

# Process datasets
python3 python_preprocessing/process_datasets.py --dataset all

# Train models
python3 python_preprocessing/train_models.py --dataset alexa
python3 python_preprocessing/train_models.py --dataset twitter
```

### 5. Start Development

```bash
# Start Next.js development server
npm run dev

# In another terminal, keep Python environment ready
source python_preprocessing/venv/bin/activate
```

## ğŸ“š Usage Guide

### Web Interface

1. **Text Processing Demo** (`/preprocessing`)
   - Enter text in the input area
   - Click "Process Text" to see step-by-step preprocessing
   - View cleaning, normalization, and tokenization results

2. **File Upload** (`/analyze`)
   - Drag and drop text files or use the file picker
   - Supports CSV, TSV, TXT, JSON formats
   - Real-time validation and error handling

3. **Analysis Dashboard** (`/dashboard`)
   - View processed data statistics
   - Interactive charts and visualizations
   - Export results in multiple formats

### Python Pipeline

```bash
# Process custom dataset
python3 python_preprocessing/process_datasets.py --dataset custom --file path/to/your/data.csv

# Train models on processed data
python3 python_preprocessing/train_models.py --dataset custom

# Run integration tests
python3 python_preprocessing/test_preprocessing_integration.py
```

### API Integration

```python
from python_preprocessing.text_preprocessor import TextPreprocessor
import joblib

# Initialize preprocessor
preprocessor = TextPreprocessor()

# Process text
cleaned, normalized, tokens = preprocessor.preprocess_text("Your text here")

# Load trained model
model = joblib.load("python_preprocessing/trained_models/alexa_best_model.pkl")

# Make predictions
# (Feature extraction and prediction code)
```

## ğŸ“ Project Structure

```
AI-Narrative-Nexus/
â”‚
â”œâ”€â”€ ğŸŒ Frontend (Next.js)
â”‚   â”œâ”€â”€ app/                     # Next.js pages
â”‚   â”‚   â”œâ”€â”€ analyze/            # File upload interface
â”‚   â”‚   â”œâ”€â”€ preprocessing/      # Text processing demo
â”‚   â”‚   â”œâ”€â”€ dashboard/          # Analytics dashboard
â”‚   â”‚   â””â”€â”€ results/           # Analysis results
â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”‚   â”œâ”€â”€ ui/                # UI components (buttons, cards, etc.)
â”‚   â”‚   â”œâ”€â”€ visualizations/    # Charts and graphs
â”‚   â”‚   â””â”€â”€ *.tsx              # Feature components
â”‚   â””â”€â”€ styles/                # CSS and styling
â”‚
â”œâ”€â”€ ğŸ¤– Backend (Python ML)
â”‚   â”œâ”€â”€ python_preprocessing/   # ML pipeline
â”‚   â”‚   â”œâ”€â”€ text_preprocessor.py    # Core preprocessing
â”‚   â”‚   â”œâ”€â”€ process_datasets.py     # Batch processing
â”‚   â”‚   â”œâ”€â”€ train_models.py         # Model training
â”‚   â”‚   â”œâ”€â”€ processed_data/         # ML-ready datasets
â”‚   â”‚   â”œâ”€â”€ trained_models/         # Serialized models
â”‚   â”‚   â””â”€â”€ venv/                   # Python environment
â”‚   â””â”€â”€ setup_preprocessing.sh  # Automated setup
â”‚
â”œâ”€â”€ ğŸ“Š Data
â”‚   â”œâ”€â”€ dataset/               # Raw datasets
â”‚   â””â”€â”€ public/               # Static assets
â”‚
â”œâ”€â”€ ğŸ“– Documentation
â”‚   â”œâ”€â”€ README.md             # This file
â”‚   â”œâ”€â”€ PREPROCESSING_REQUIREMENTS_COMPLETE.md
â”‚   â”œâ”€â”€ PYTHON_PREPROCESSING_REPORT.md
â”‚   â””â”€â”€ CLEANUP_SUMMARY.md
â”‚
â””â”€â”€ âš™ï¸ Configuration
    â”œâ”€â”€ package.json          # Node.js dependencies
    â”œâ”€â”€ tsconfig.json         # TypeScript config
    â”œâ”€â”€ next.config.mjs       # Next.js config
    â””â”€â”€ .gitignore           # Git ignore rules
```

## ğŸ”§ Development

### Building for Production

```bash
# Build the Next.js application
npm run build

# Start production server
npm start
```

### Running Tests

```bash
# Test Python preprocessing pipeline
source python_preprocessing/venv/bin/activate
python3 python_preprocessing/test_preprocessing_integration.py

# Test specific dataset processing
python3 python_preprocessing/process_datasets.py --dataset alexa
```

### Code Quality

```bash
# TypeScript type checking
npm run build

# Python code formatting (if using black)
pip install black
black python_preprocessing/
```

## ğŸš€ Production Deployment

### Environment Variables

Create a `.env.local` file:

```env
# Next.js
NEXT_PUBLIC_APP_URL=https://your-domain.com

# Python ML Pipeline
PYTHON_ENV=production
MODEL_PATH=/path/to/models
```

### Docker Setup (Optional)

```dockerfile
# Example Dockerfile structure
FROM node:20-alpine AS frontend
# ... frontend build steps

FROM python:3.13-slim AS backend
# ... Python environment setup

FROM nginx:alpine AS production
# ... combined deployment
```

### Deployment Checklist

- [ ] Environment variables configured
- [ ] Python models trained and serialized
- [ ] Static assets optimized
- [ ] Database connections configured (if applicable)
- [ ] SSL certificates installed
- [ ] Monitoring and logging setup

## ğŸ“ˆ Performance Benchmarks

| Metric | Value | Notes |
|--------|--------|-------|
| **Text Processing** | 6,000-7,000 records/sec | NLTK pipeline |
| **Model Accuracy** | 94% (reviews), 71% (social) | Various datasets |
| **Build Time** | ~30-60 seconds | Next.js optimization |
| **Bundle Size** | ~140KB first load | Optimized components |
| **Memory Usage** | ~10-50MB | Per 10K records |

## ğŸ¤ Contributing

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Guidelines

- Follow TypeScript best practices
- Write comprehensive tests for new features
- Update documentation for API changes
- Ensure Python code follows PEP 8
- Test preprocessing pipeline with sample data

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Documentation**: Check the `/docs` folder for detailed guides
- **Issues**: Report bugs via GitHub Issues
- **Discussions**: Use GitHub Discussions for questions
- **Email**: Contact the development team

## ğŸ‰ Acknowledgments

- **NLTK Team** for comprehensive NLP tools
- **scikit-learn** for machine learning algorithms
- **Next.js Team** for the excellent React framework
- **Radix UI** for accessible component primitives
- **Vercel** for deployment and hosting solutions

---

**ğŸš€ Ready to analyze text data like never before!**

*Built with â¤ï¸ by the AI Narrative Nexus Team*
